---
title: "Autor: Sergi Sánchez Romero y Lucia Blanc Velázquez"
author: "Diciembre 2023"
date: ""
output:
  html_document: 
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: PEC-header.html
  pdf_document: 
    highlight: zenburn
    toc: yes
    always_allow_html: true  
  word_document: default
---

******
<h2 style="background-color: #0E4D83; color: white;">1. Introducción</h2> 
******


<h3 style="background-color: #2677AF; color: white;">1.1. Presentación</h3>

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de los mismos.


<h3 style="background-color: #2677AF; color: white;">1.2. Objetivos</h3>

● Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.

● Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.

● Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.

● Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.

● Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.

● Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.

● Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.






******
<h2 style="background-color: #0E4D83; color: white;">2. Descripción del dataset: "Heart Attack Analysis & Prediction dataset"</h2> 
******
El conjunto de datos escogido para esta práctica, se titula: “Heart Attack Analysis & Prediction dataset”, el cual tiene como objetivo detectar aquellos factores que pueden actuar como potenciales precursores de las enfermedades cardiovasculares, y así ayudar a la detección y gestión temprana mediante la creación de un modelo. 
En el conjunto de datos se contemplan un total de 14 características importantes, tanto numéricas como categóricas que pueden ayudar a la predicción de desarrollar o no una enfermedad cardíaca. Según la información encontrada, se sabe que las enfermedades cardiovasculares ocupan un porcentaje del 31% en relación a las muertes que se producen en el mundo cada año, por lo que supone una de las causas principales de muerte. La variable 'output', consiste en valores de 0 o 1 que indican si una persona tiene más probabilidad de sufrir un infarto (1) o menor probabilidad (0).
Es importane tener en cuenta cuales son los atributos que pueden conllevar a un mayor riesgo cardiovascular o al desarrollo de enfermedad cardiovascular, por lo que, el objetivo es predecir que variables influyen más en este desarrollo.



A continuación, realizamos la descripción de las variables que hay en el dataset "Heart Attack Analysis & Prediction dataset", usando la información encontrada en la web [Kaggle datasets] (https://www.kaggle.com/datasets), concretamente en el siguiente enlace: https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset 

** Características de las variales incluidas:**

+ **age**: Edad del paciente

+ **sex** : Sexo del paciente (F=0; M=1)

+ **cp** : Tipo dolor torácico

  -  **Value 1** : Angina típica (TA)

  - **Value 2** : Angina atípica (ATA)

  - **Value 3** : Dolor no-anginal (NAP)

  - **Value 4** : Asintomático (ASY)

+ **trtbps** : Presión arterial en reposo (in mm Hg)

+ **chol** : Colesterol en mg/dl obtenido a través del sensor de IMC 

+ **fbs** : (Glucemia en ayunas > 120 mg/dl) (1 = true; 0 = false)

+ **restecg** : Resultados del electrocardiograma en reposo 

  - **Value 0** : Normal

  - **Value 1** : Presentar anomalías de la onda ST-T (inversión de la onda T y/o elevación o depresión del ST de > 0,05 mV)

  - **Value 2** : Hipertrofia ventricular izquierda probable o definida según los criterios de Estes

+ **thalachh** : Frecuencia cardiaca máxima alcanzada 

+ **exng** : Angina inducida por esfuerzo (1 = yes; 0 = no)

+ **oldpeak** : Pico previo

+ **slp** : Pendiente del segmento ST máximo del ejercicio

+ **caa** : Número de buques principales (0-3)

+ **thall** : Tasa de mortalidad

+ **output** : 0= menor probabilidad de infarto 1= mayor probabilidad de infarto 



\newpage

******
<h2 style="background-color: #0E4D83; color: white;">3. Integración y selección de los datos de interés a analizar</h2> 
******
Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos originales, en base al objetivo que se quiera conseguir.


Primero de todo, cargamos las librerías que vamos a usar durante la práctica
```{r message= FALSE, warning=FALSE}

if (!require('dplyr')) install.packages('dplyr');library(dplyr)
if (!require('ggplot2')) install.packages('ggplot2');library(ggplot2)
if (!require('reshape')) install.packages('reshape');library(reshape)
if (!require('plotly')) install.packages('plotly');library(plotly)
if (!require('plyr')) install.packages('plyr');library(plyr)
if (!require('Stat2Data')) install.packages('Stat2Data');library(Stat2Data)
if (!require('corrplot')) install.packages('corrplot');library(corrplot)
if (!require('Matrix')) install.packages('matrix');library(Matrix)
if (!require('patchwork')) install.packages('patchwork');library(patchwork)
if (!require('ggcorrplot')) install.packages('ggcorrplot');library(ggcorrplot)
if (!require('corrplot')) install.packages('ggcorrplot');library(corrplot)
if (!require('DataExplorer'))install.packages('DataExplorer');library(DataExplorer)
if (!require('psych'))install.packages('psych');library(psych)
if (!require('highcharter'))install.packages('highcharter');library(highcharter)
if (!require('tidyverse'))install.packages('tidyverse');library(tidyverse)
if (!require('GGally'))install.packages('GGally');library(GGally)
if (!require('htmltools'))install.packages('htmltools');library(htmltools)

# setwd
dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(dir)
```


<h3 style="background-color: #2677AF; color: white;">Carga del dataset</h3>
Cargamos los datos de la base de datos "heart" y tipificamos las variables que tiene el conjunto de datos como corresponde
```{r}
library(readxl)
heart <- read_excel("heart.xlsx")


# Mostramos los primeros registros del conjunto de dtos, con el fin de ver una aproximación de como es el conjunto y su estructura
head(heart, max(10))
str(heart)
```
El conjunto de datos consiste en 14 variables numéricas (columnas continuas).




******
<h2 style="background-color: #0E4D83; color: white;">4.Limpieza de los datos</h2>
******

<h3 style="background-color: #2677AF; color: white;">Classificación de variables</h3>
```{r}
library(dplyr)
# Clasificamos las variables en numéricas o en categóricas
# Numéricas
heart <- heart%>%
  mutate_at(vars(age,trtbps,chol, thalachh, oldpeak), as.numeric)

# Categóricas
heart <- heart%>%
  mutate_at(vars(sex, cp, fbs, restecg, exng, slp, thall, caa, output), as.character)


# Observamos las dimensiones del dataset "heart"
heart.cols<-dim(heart)[2]
heart.rows<-dim(heart)[1]

# Obtenemos un primer vistazo estadístico de cada atirbuto
describeBy(heart)
```


<h3 style="background-color: #2677AF; color: white;">Dimensión del conjunto de datos</h3>

Con la librería DataExplorer vemos una vista general del conjunto de datos de análisis una vez seleccionados, basandonos en los valores faltantes, columnas discretas y continuas.
```{r}
library(DataExplorer)
plot_intro(heart, title = "Información Dataset")
introduce(heart)
```
Según la tabla y el barplot creado, podemos ver como el conjunto de datos heart tiene 14 atributos y 303 observaciones, el cual contiene un total de 9 columnas discretas y 5 columnas continuas.
Observamos como no hay valores faltantes.



Ahora vamos a visualizar la información básica del conjunto de datos en función de la variable 'output' de interés
```{r}
# La variable output nos va indicar quien tiene o no una mayor probabilidad de sufrir un ataque al corazón, por lo que primero calculamos el porcentaje de pacientes que tienen mayor probabilidad y luego el resto

print("Porcentaje de personas con probabilidad de infarto")
round((sum(heart$output == 1)/nrow(heart)) * 100, 2)


print("Porcentaje de personas sin probabilidad de infarto")
round((sum(heart$output == 0)/nrow(heart))*100,2)
```



<h3 style="background-color: #2677AF; color: white;">Arreglamos el conjunto de datos</h3>


Primero de todo, hacemos una matriz de correlaciones de todo el conjunto
<h4 style="background-color: #2677AF; color: white;">Matriz de Correlaciones</h4>
```{r}
# Convirtimos todas las variables a numéricas (asegúrate de que las variables sean numéricas)
heart_numeric <- sapply(heart, as.numeric)

 # Calculamos la matriz de correlación
correlation_tab <- cor(heart_numeric)

library(RColorBrewer)

# Definimos una nueva paleta de colores
new_col <- colorRampPalette(c("#0000CD", "#7D26CD", "#FFFFFF","#FF6347","#FF0000"))

# Creamos la matriz de correlación con corrplot y personalización adicional
corrplot(correlation_tab, 
         method = "color", 
         tl.col = "black", 
         tl.srt = 45, 
         tl.cex = 0.8, 
         cl.cex = 0.8, 
         col = new_col(200), 
         addCoef.col = "black", 
         order = "AOE", 
         number.cex = 0.8,
         title = "Matriz de Correlación") 
```




<h4 style="background-color: #2677AF; color: white;">Valores Duplicados</h4>
```{r}
# Valores duplicados
get_duplicates <- function(heart){
    total_rows = dim(heart)[1]
    unique_rows = dim(heart %>% group_by_all %>% count)[1]
    n_duplicates = (total_rows - unique_rows)
    cat('n duplicates -> ', n_duplicates)
}

get_duplicates(heart) # Vemos que hay un valor duplicado

heart = unique(heart)


cat('Eliminamos la fila duplicada')

get_duplicates(heart)
```
Ya no tenemos valores duplicados en el conjunto de datos










<h3 style="background-color: #2677AF; color: white;">Análisis Univariado</h3>


<h4 style="background-color: #2677AF; color: white;">Variables Categóricas</h4>

Primero discretizaremos las variables categóricas, asignando a cada valor la correspondiente definición de la variable
```{r}
# Hacemos cópia del conjunto para usarlo solamente en este análisis:
heart_discr<-heart

# Sexo del paciente (sex)
heart_discr$sex <- ifelse(heart_discr$sex == 0, "Mujer", "Hombre")

# Dolor Torácico (cp)
heart_discr$cp <- factor(heart_discr$cp, levels = c(1, 2, 3, 4), labels = c("Angina Típica", "Angina Atípica", "No Anginal", "Asintomático"))

# Resultados del Electrocardiograma en Reposo (restecg)
heart_discr$restecg <- factor(heart_discr$restecg, levels = c(0, 1, 2), labels = c("Normal", "Anomalías ST-T", "Hipertrofia ventricular"))

# Angina Inducida por Esfuerzo (exng)
heart_discr$exng <- ifelse(heart_discr$exng == 1, "Si", "No")

# Número de Buques Principales (caa) (0-3)
heart_discr$caa <- as.character(heart_discr$caa)

# Glucemia en Ayunas (fbs)
heart_discr$fbs <- ifelse(heart_discr$fbs == 1, "Verdadero", "Falso")

# Pendiente del Segmento ST Máximo del Ejercicio (slp)
heart_discr$slp <- factor(heart_discr$slp, levels = c(0, 1, 2), labels = c("Tipo 0", "Tipo 1", "Tipo 2"))

# Tasa de Mortalidad (thall)
heart_discr$thall <- factor(heart_discr$thall, levels = c(0, 1, 2, 3), labels = c("Thal0", "Thal1", "Thal2", "Thal3"))

# Ouput/Target (0= menor probabilidad de infarto 1= mayor probabilidad de infarto)
heart_discr$output <- factor(heart_discr$output, levels = c(0, 1), labels = c("Menor probabilidad", "Mayor probabilidad"))
```



A continuación estudiamos la estadística básica de las variables categóricas del conjunto heart
```{r}
library(dplyr)
library(ggplot2)


par(mfrow = c(2, 2))

categorical_var <- list("sex", "cp", "fbs", "restecg", "exng", "slp", "caa", "thall")

for (i in categorical_var) {
  plot_data <- as.data.frame(table(heart_discr[[i]], heart_discr$output))
  colnames(plot_data) <- c(i, "output", "Freq")
  
  plot <- ggplot(plot_data, aes_string(x = i, y = "Freq", fill = "output")) +
    geom_bar(stat = "identity", position = position_dodge()) +
    scale_fill_manual(values = c("#BA55D3", "#6699CC"), 
                      name = "Probabilidad de Infarto", 
                      labels = c('0-Menor', '1-Mayor')) +
    labs(x = i, y = "Número de Observaciones") +
    theme_minimal() +  # Cambio de tema a minimal
    theme(panel.background = element_rect(fill = "white"),  # Fondo blanco
          axis.line = element_line(color = "black"))  # Líneas de ejes negras
  
  print(plot)
}

```

**Observaciones**

Según el thall, el riesgo de infarto se alcanza en las personas con frecuencia cardíaca máxima(clase 2).
En la característica sexo, la clase 1 tiene más posibilidades de sufrir un infarto que la clase 0.
Las probabilidades de sufrir un infarto son mayores en la clase 0 de sexo.
Comparando con el análisis de correlación, la característica fbs muestra la menor correlación con la salida.
En caa, las personas con clase, son más propensas a sufrir un ataque al corazón que las personas con clase 4, 3 y 2.
Según la característica cp, las personas con dolor no anginoso tienen más probabilidades de sufrir un infarto que las personas con dolor anginoso atípico y típico.
En exng, las personas con clase 1 tienen altas probabilidades de riesgo de infarto, mientras que las personas con clase 0 son menos propensas al infarto.
La característica Slp muestra que la clase 0 tiene menos correlación con el resultado que las clases 1 y 2.









<h4 style="background-color: #2677AF; color: white;">Variables Numéricas</h4>
A continuación estudiamos la estadística básica de las variables numéricas del conjunto
```{r}
# Creamos un gráfico de pares con las variables numéricas del conjunto de datos "heart"
# Establecer opciones para el tamaño del gráfico
options(repr.plot.width = 20, repr.plot.height = 20)  

# Creamos un gráfico de pares con las variables numéricas del conjunto de datos "heart"
pair_plot <- ggpairs(heart, columns = c("age", "trtbps", "chol", "thalachh", "oldpeak"),
                     aes(color = as.factor(output), alpha = 0.5),
                     lower = list(continuous = "smooth"),
                     palette = c('blue', 'red')) +  # Usamos la misma paleta de colores
  theme_bw() +
  theme(text = element_text(size = 8),
        panel.grid = element_blank(),
        legend.position = "right",
        legend.title = element_text(face = "bold")) +
  ggtitle("Variables Numéricas") +
  labs(color = "Output", alpha = "Transparencia")
pair_plot
# Convertimos el gráfico a un gráfico interactivo con plotly
interactive_plot <- ggplotly(pair_plot)

# Mostramos el gráfico interactivo
interactive_plot

```





<h3 style="background-color: #2677AF; color: white;">Valores Outliers</h3>

Seguidamente es importante estudiar la posibilidad de valores outliers para las variables numéricas de la base de datos
```{r}
# Cargamos librerías necesarias
library(ggplot2)

# Reorganizamos el dataframe para plotear las variables seleccionadas
selected_vars <- heart[, c("age", "oldpeak", "chol", "thalachh", "trtbps")]
selected_vars <- stack(selected_vars)

# Agregamos la columna 'output' al dataframe para usarla en el color de los puntos
selected_vars$output <- heart$output

# Creamos un gráfico de cajas con puntos superpuestos para las variables numéricas seleccionadas
ggplot(selected_vars, aes(x = ind, y = values, color = as.factor(output))) +
  geom_boxplot(alpha = 0.7, outlier.size = 2) +  
  geom_jitter(alpha = 0.3, size = 0.5) +  
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  
  labs(x = "Variables", y = "Valores") +
  scale_color_brewer(palette = "Set1", name = "Probabilidad de Infarto", labels = c('0 - Menor Probabilidad', '1 - Mayor Probabilidad')) + 
  ggtitle("Gráfico de Cajas con Puntos - Variables Numéricas y Outliers")


```
**Observaciones**
Podemos ver como hay puntos muy alejados de las medias y de los boxplots creados en las variables chol, thalachh y trtbps, por lo que, vamos a estudiar si mediante una función creada según las desviaciones estandard, se eliminan estos valores y dejamos el conjunto de datos sin potenciales valores outliers.


<h3 style="background-color: #2677AF; color: white;">Limpieza de outliers </h3>
Para limpiar los outliers usamos un enfoque de desviaciones estándar (SD), el cual usa la distribución normal de los datos.
```{r}
# Creamos un dataframe de las variables de las cuales hemos de quitar outliers, excluyendo age y oldpeak
df_outliers<-as.data.frame(heart %>%
                  select("trtbps","thalachh","chol"))

# Función para quitar outliers
remove_outliers_sd <- function(df_outliers, threshold = 5) {
  # Loop a través de cada columna numérica del dataframe
  for (col in names(df_outliers)) {
    if(is.numeric(df_outliers[[col]])) {
      col_mean <- mean(df_outliers[[col]], na.rm = TRUE)
      col_sd <- sd(df_outliers[[col]], na.rm = TRUE)
      df_outliers <- df_outliers[abs((df_outliers[[col]] - col_mean) / col_sd) <= threshold, ]
    }
  }
  df_outliers
}


heart_clean <-remove_outliers_sd(heart,c("trtbps" ,"thalachh", "chol"))

# Observamos el cambio de las dimensiones
dim(heart_clean)
```
Los valores potenciales outliers no han sido eliminados debido que pueden ser posibles valores de las variables, con lo que, tenemos el conjunto de datos limpio y nos hemos asegurado de que no hay ningún valor que se aleje de la realidad. 







******
<h2 style="background-color: #0E4D83; color: white;">5. Análisis de los datos</h2>
******


## Selección de los grupos de datos que se quieren analizar/comparar 
(p.ej., si se van a comparar grupos de datos, ¿cuáles son estos grupos y qué tipo de análisis se van a aplicar?)


Para analizar y comparar los datos seleccionados, dividiremos el enfoque en tres partes, centrándonos en la predicción de ataques cardíacos (variable "output") en relación con las variables de interés.
Dividiremos el análisis en tres partes sobre las variables que anteriormente hemos seleccionado. El objetivo y la respuesta a contestar es el tratar de aclarar que tipo de condiciones ayudan a predecir con mejor medida un ataque al corazón. 


Los análisis que realizaremos son los siguientes

Matriz de Correlaciones: Exploraremos las relaciones lineales entre todas las variables seleccionadas. Este análisis nos mostrará cómo se correlacionan entre sí las variables, permitiendo identificar asociaciones y patrones de relación, lo que podría sugerir qué variables están más estrechamente relacionadas con la presencia de ataques cardíacos.

ANOVA (Análisis Comparativo): Evaluaremos la diferencia en la variable de salida ("output") en función de todas las variables incluidas también en la matriz de correlación. Esto nos permite determinar si hay diferencias significativas en la media de "output" entre los distintos niveles de estas variables.

Modelo Predictivo (Regresión Logística): Utilizaremos una regresión logística para predecir la ocurrencia de ataques cardíacos ("output") basándonos en las variables con una correlación relevante en la matriz anterior. Analizaremos variables como el tipo de dolor torácico, frecuencia cardíaca máxima alcanzada, tasa de mortalidad, angina inducida por el ejercicio, pendiente del segmento ST máximo del ejercicio y el número de grandes buques. El objetivo es comprender qué variables son predictivas de ataques cardíacos y en qué medida influyen en la predicción.

Estos análisis proporcionarán una visión detallada sobre cómo las diferentes variables están relacionadas con la presencia de ataques cardíacos y qué factores pueden ser más relevantes para predecirlos.


## Comprobación de la normalidad y homogeneidad de la varianza.

### Comprobación de Normalidad
Para evaluar la normalidad de las variables seleccionadas, empleamos la prueba de Spahiro-Wilk
```{r}
# Una vez tenemos los datos discretizados, comprobamos la normalidad

# Usamos la prueba de Shapiro-Wilk para verificar la normalidad de cada variable numérica
variables <- c("age", "trtbps", "chol", "thalachh", "oldpeak")
resultados_shapiro <- lapply(heart_clean[variables], shapiro.test)
names(resultados_shapiro) <- variables

# Verificar la estructura de las variables seleccionadas en el conjunto de datos 'heart'
str(heart_clean[, variables])
# Mostramos los resultados
print(resultados_shapiro)

```
Los resultados de la normalidad muestran que para la variable 'age' (edad) hay evidencia suficiente para rechazar la hipótesis nula y afirmar que los datos no siguen una distribución normal, igual que la variable 'trtbps' (presión arterial en reposo) y la variable 'oldpeak', donde la evidencia para rechazar la hipótesis de normalidad es más fuerte. 

Por otro lado, ni la variable 'chol' (colesterol) ni la variable 'thalachh' (ritmo cardíaco máximo aclanzada) muestran suficiente evidencia para rechazar la hipótesis nula de normalidad, sugiriendo que los datos de ambas variables podrían seguir una distribución normal. 


### Comprobación de Varianza
Calculamos las varianzas de las variables numéricas agrupadas por categorías de edad. 
Esto nos va a proporcionar una visión de como varían  'age', 'trtbps', 'chol', 'thalachh', y 'oldpeak'  en distintos grupos de edad en el riesgo de sufrir un ataque cardíaco.
```{r}

```


Clasificamos la varible 'output' en dos categorías ('Yes' y 'No) para investigar las varianzas de las variables numéricas respecto a la probabilidad de sufrir un ataque cardíaco
```{r}

```
Los resultados resaltan las diferencias en las varianzas de estas variables entre aquellos casos con mayor probabilidad de sufrir un ataque cardíaco y los que no.

Esta evaluación proporciona una visión detallada de cómo las variables numéricas varían en relación con la edad y la probabilidad de sufrir un ataque cardíaco, lo que puede ser fundamental para comprender los factores de riesgo asociados





## Aplicación de pruebas estadísticas para comparar los grupos de datos


### Analísis comparativo (ANOVA)

Para realizar un análisis comparativo de todas las variables numéricas y la variable output, empleamos la prueba estadística de ANOVA, prueba que evalúa si hay diferencias significativas en la media de la variable de salida entre los distintos niveles de las variables numéricas.



Parece que la frecuencia cardíaca máxima alcanzada (thalachh), el número de grandes vasos (caa), el tipo de dolor de pecho (cp), la presencia de angina inducida por el ejercicio (exng) y, en menor medida, el tipo de pendiente del segmento ST del electrocardiograma en reposo (slp), la tasa de mortalidad (thall) y la depresión inducida por el ejercicio (oldpeak), muestran asociaciones significativas con la presencia de enfermedades cardíacas. Estos hallazgos, indicados por los valores de p altamente significativos , podrían sugerir la importancia de estas variables en la predicción o diagnóstico de enfermedades cardíacas en el conjunto de datos analizado.

Por otro lado, variables como la edad (age), el sexo (sex), el nivel de azúcar en sangre en ayunas (fbs), el resultado del electrocardiograma en reposo (restecg), la presión arterial en reposo (trtbps) y el colesterol (chol) no parecen demostrar una asociación significativa con la variable de salida (output) en este análisis, ya que sus valores p no alcanzan niveles de significancia estadística.

Estos resultados proporcionan una visión inicial sobre qué variables podrían ser más relevantes al abordar problemas relacionados con enfermedades cardíacas en este contexto específico. Sin embargo, es importante tener en cuenta que estos hallazgos pueden requerir una validación adicional o un análisis más detallado para confirmar su relevancia clínica o predictiva, como lo haremos a continuación mediante un modelo de regresión logística



### Modelado Predictivo (Regresión logística)
Para construir un modelo predictivo usando regresión logística con las variables seleccionadas del ANOVA anterior, usamos la función glm().
```{r}

```
El modelo de regresión logística tiene como objetivo predecir la probabilidad de ocurrencia de enfermedades cardíacas (output) a partir de un conjunto de variables predictoras (cp, thalachh, thall, oldpeak, exng, slp y caa).

+ **cp (Tipo de dolor torácico)** : Existe una relación positiva significativa entre el tipo de dolor torácico y la probabilidad de enfermedades cardíacas (coeficiente 1.39852, p-valor 0.00572). Los mayores niveles de este tipo de dolor están asociados con un aumento en la probabilidad de enfermedades cardíacas.
+ **thalachh (Frecuencia cardíaca máxima alcanzada)** : No se encuentra una asociación significativa (coeficiente 0.02113, p-valor 0.36625) con la ocurrencia de enfermedades cardíacas en este modelo. Es importante tener en cuenta que su efecto parece no ser significativo en la predicción de enfermedades cardíacas.
+ **thall (Tasa de mortalidad)** : Muestra una relación negativa significativa con las enfermedades cardíacas (-1.62496, p-valor 0.02521). Niveles más altos de esta variable se relacionan con una disminución en la probabilidad de enfermedades cardíacas.
+ **exng (Angina inducida por el ejercicio)** : No muestra una relación significativa (p-valor alto: 0.82945) con la presencia de enfermedades cardíacas en este modelo. No parece ser un factor determinante en la predicción de enfermedades cardíacas según este análisis.
+ **slp (Pendiente del segmento ST máximo del ejercicio)** : Indica una posible asociación positiva (coeficiente 1.49037), aunque no es estadísticamente significativa al 95% (p-valor 0.10608). Esta variable podría tener cierta influencia en la probabilidad de enfermedades cardíacas, aunque se requiere precaución al interpretar su efecto debido a su p-value relativamente alto.
+ **caa (Número de grandes vasos)** : Muestra una posible relación negativa (-1.05345), aunque no es estadísticamente significativa al 95% (p-valor 0.07702). Su efecto en la predicción de enfermedades cardíacas parece sugerir una disminución en la probabilidad, pero se necesitarían más datos para confirmar su influencia.
+ **oldpeak (Depresión inducida por el ejercicio)** : En este modelo, la variable "oldpeak" no muestra una asociación significativa (coeficiente 0.03849, p-valor 0.92685) con la presencia de enfermedades cardíacas. Según este análisis, la depresión del segmento ST inducida por el ejercicio no parece influir en la probabilidad de ocurrencia de enfermedades cardíacas.

En resumen, las variables "cp" (Tipo de dolor torácico) y "thall" (Tasa de mortalidad) parecen ser las más influyentes para predecir la ocurrencia de enfermedades cardíacas en este modelo. Otras variables como "slp", "caa", "thalachh" y "exng" muestran asociaciones que podrían ser relevantes a diferentes niveles de confianza o podrían necesitar más datos para una conclusión más sólida.

El AIC del modelo es 58.647, lo que sugiere que este modelo podría mejorar con ajustes adicionales o la inclusión de más variables predictoras. La deviance residual es significativamente menor que la deviance nula, indicando que las variables incluidas en el modelo explican parte de la variabilidad en la presencia de enfermedades cardíacas.



<h2 style="background-color: #0E4D83; color: white;">6.Resolución del problema</h2>

Los hallazgos de este análisis proporcionan claridad sobre las variables más relevantes para predecir la ocurrencia de enfermedades cardíacas.


El tipo de dolor torácico (cp) y la tasa de mortalidad (thall) emergen como indicadores significativos de enfermedades cardíacas, mostrando asociaciones claras con la presencia de esta condición en el análisis de regresión logística. Además, la frecuencia cardíaca máxima alcanzada (thalachh) y el número de grandes vasos (caa) también muestran vínculos potenciales, aunque su confirmación estadística podría requerir más datos.

La angina inducida por el ejercicio (exng) y la pendiente del segmento ST máximo del ejercicio (slp) no presentan asociaciones estadísticamente significativas con la presencia de enfermedades cardíacas según este análisis.

La depresión inducida por el ejercicio (oldpeak), aunque no muestra asociación significativa, no parece influir en la probabilidad de ocurrencia de enfermedades cardíacas en este modelo.

Estos resultados subrayan la importancia del dolor torácico y la tasa de mortalidad como predictores potenciales de enfermedades cardíacas. Sin embargo, se destaca la necesidad de mayor validación para algunas variables y la posibilidad de ajustes adicionales en el modelo, ya que algunos factores podrían tener influencias más sutiles o necesitar mayor evidencia para confirmar su contribución a la predicción de esta condición médica.
